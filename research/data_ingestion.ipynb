{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c3ca7af",
   "metadata": {},
   "source": [
    "# data Ingestion "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "96d9c091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants\n",
    "import os \n",
    "import sys \n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "\"\"\" \n",
    "defining common constant variable for training pipeline \n",
    "\"\"\"\n",
    "TARGET_COLUMN='Result'\n",
    "PIPELINE_NAME: str='NetworkSecurity'\n",
    "ARTIFACT_DIR: str= 'Artifacts'\n",
    "FILE_NAME: str = 'phisingData.csv'\n",
    "TRAIN_FILE_NAME: str='train.csv'\n",
    "TEST_FILE_NAME: str='test.csv'\n",
    "\n",
    "\n",
    "\"\"\" \n",
    "Data Ingestion related constants starts with DATA_INGESTION VAR NAME \n",
    "\"\"\"\n",
    "DATA_INGESTION_COLLECTION_NAME: str = 'NetworkData'\n",
    "DATA_INGESTION_DATABASE_NAME: str = 'IMMORTALPI'\n",
    "DATA_INGESTION_DIR_NAME: str= 'data_ingestion'\n",
    "DATA_INGESTION_FEATURE_STORE_DIR: str='feature_store'\n",
    "DATA_INGESTION_INGESTED_DIR: str='ingested'\n",
    "DATA_INGESION_TAIN_TEST_SPLIT_RATIO: float=0.2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04333139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# artifacts entity\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class DataIngestionArtifact:\n",
    "    trained_file_path:str \n",
    "    test_file_path:str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6a6006a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entity \n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class DataIngestionArtifact:\n",
    "    trained_file_path:str \n",
    "    test_file_path:str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29881e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config entity \n",
    "from datetime import datetime\n",
    "import os \n",
    "from NetworkSecurity.constants import training_pipeline \n",
    "\n",
    "class TrainingPipelineConfig:\n",
    "    def __init__(self, timestamp=datetime.now()):\n",
    "        timestamp=timestamp.strftime('%m_%d_%Y_%H_%M_%S')\n",
    "        self.pipeline_name=training_pipeline.PIPELINE_NAME\n",
    "        self.artifact_name=training_pipeline.ARTIFACT_DIR\n",
    "        self.artifact_dir=os.path.join(self.artifact_name,timestamp)\n",
    "        self.timestamp: str=timestamp\n",
    "        \n",
    "\n",
    "class DataIngestionConfig:\n",
    "    def __init__(self,training_pipeline_config:TrainingPipelineConfig):\n",
    "        self.data_ingestion_dir:str=os.path.join(\n",
    "            training_pipeline_config.artifact_dir,training_pipeline.DATA_INGESTION_DIR_NAME\n",
    "        )\n",
    "        self.feature_store_file_path: str=os.path.join(\n",
    "            self.data_ingestion_dir,training_pipeline.DATA_INGESTION_FEATURE_STORE_DIR,training_pipeline.FILE_NAME\n",
    "        )\n",
    "        self.training_file_path: str=os.path.join(\n",
    "            self.data_ingestion_dir,training_pipeline.DATA_INGESTION_INGESTED_DIR, training_pipeline.TRAIN_FILE_NAME\n",
    "        )\n",
    "        self.training_file_path: str=os.path.join(\n",
    "            self.data_ingestion_dir,training_pipeline.DATA_INGESTION_INGESTED_DIR, training_pipeline.TRAIN_FILE_NAME\n",
    "        )\n",
    "        self.test_file_path: str=os.path.join(\n",
    "            self.data_ingestion_dir,training_pipeline.DATA_INGESTION_INGESTED_DIR, training_pipeline.TEST_FILE_NAME\n",
    "        )\n",
    "        self.train_test_split_ratio:float=training_pipeline.DATA_INGESION_TAIN_TEST_SPLIT_RATIO\n",
    "        self.collection_name:str=training_pipeline.DATA_INGESTION_COLLECTION_NAME\n",
    "        self.database_name:str=training_pipeline.DATA_INGESTION_DATABASE_NAME\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "834fe1fc",
   "metadata": {},
   "source": [
    "# component\n",
    "- read the data from mongodb \n",
    "- create a feature store \n",
    "- create split the data into train and test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53c3a564",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from NetworkSecurity.exception.exception import NetworkSecurityException\n",
    "from NetworkSecurity.logging.logger import logging\n",
    "import os \n",
    "import sys \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pymongo\n",
    "from typing import List\n",
    "from sklearn.model_selection import train_test_split \n",
    "\n",
    "#config of data ingestion \n",
    "#enter the config filepath \n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "MONGO_DB_URL=os.getenv('MONGODB_URI')\n",
    "\n",
    "class DataIngestion:\n",
    "    def __init__(self, data_ingestion_config:DataIngestionConfig):\n",
    "        try:\n",
    "            self.data_ingestion_config=data_ingestion_config\n",
    "        except Exception as e:\n",
    "            raise NetworkSecurityException(e,sys)\n",
    "        \n",
    "    def export_collection_as_dataframe(self):\n",
    "        try:\n",
    "            database_name=self.data_ingestion_config.database_name\n",
    "            collection_name=self.data_ingestion_config.collection_name\n",
    "            self.mongo_client=pymongo.MongoClient(MONGO_DB_URL)\n",
    "            collection=self.mongo_client[database_name][collection_name]\n",
    "            df=pd.DataFrame(list(collection.find()))\n",
    "            if \"_id\" in df.columns.to_list():\n",
    "                df=df.drop(columns=['_id'],axis=1)\n",
    "            df.replace({'na':np.nan},inplace=True)\n",
    "            return df\n",
    "        except Exception as e:\n",
    "            raise NetworkSecurityException(e,sys)\n",
    "   \n",
    "        \n",
    "    def export_data_into_feature_store(self,dataframe:pd.DataFrame):\n",
    "        try:\n",
    "            feature_store_file_path=self.data_ingestion_config.feature_store_file_path\n",
    "            # creating folder \n",
    "            dir_path=os.path.dirname(feature_store_file_path)\n",
    "            os.makedirs(dir_path,exist_ok=True)\n",
    "            dataframe.to_csv(feature_store_file_path,index=False,header=True)\n",
    "            return dataframe\n",
    "        except Exception as e:\n",
    "            raise NetworkSecurityException(e,sys)\n",
    "        \n",
    "    def split_data_as_train_test(self,dataframe:pd.DataFrame):\n",
    "        try:\n",
    "            train_set,test_set=train_test_split(\n",
    "                dataframe,test_size=self.data_ingestion_config.train_test_split_ratio\n",
    "            )\n",
    "            logging.info('Performed train test split on the dataframe')\n",
    "            logging.info('Exited split_data_as_Train_test method of Data_Ingestion class')\n",
    "            dir_path=os.path.dirname(self.data_ingestion_config.training_file_path)\n",
    "            os.makedirs(dir_path,exist_ok=True)\n",
    "            logging.info(f'Exporting train and test file path')\n",
    "            train_set.to_csv(\n",
    "                self.data_ingestion_config.training_file_path,index=False, header=True\n",
    "            )\n",
    "            test_set.to_csv(\n",
    "                self.data_ingestion_config.test_file_path,index=False,header=True\n",
    "            )\n",
    "            logging.info(f'Exported train and test file path')\n",
    "        except Exception as e:\n",
    "            raise NetworkSecurityException(e,sys) \n",
    "\n",
    "    def initiate_data_ingestion(self):\n",
    "        try:\n",
    "            dataframe=self.export_collection_as_dataframe()\n",
    "            dataframe=self.export_data_into_feature_store(dataframe)\n",
    "            self.split_data_as_train_test(dataframe)\n",
    "            dataingestionartifact=DataIngestionArtifact(self.data_ingestion_config.training_file_path,\n",
    "                                                        self.data_ingestion_config.test_file_path)\n",
    "            return dataingestionartifact\n",
    "        except Exception as e:\n",
    "            raise NetworkSecurityException(e,sys)       \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28529032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'d:\\\\pythonProjects\\\\NetworkSecurity'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.chdir('../')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2b457ac8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataIngestionArtifact(trained_file_path='Artifacts\\\\05_03_2025_18_30_20\\\\data_ingestion\\\\ingested\\\\train.csv', test_file_path='Artifacts\\\\05_03_2025_18_30_20\\\\data_ingestion\\\\ingested\\\\test.csv')\n"
     ]
    }
   ],
   "source": [
    "# pipeline \n",
    "STAGE_NAME='DATA INGESTION STAGE'\n",
    "try:\n",
    "    logging.info(f'{STAGE_NAME} started')\n",
    "    trainingpipelineconfig=TrainingPipelineConfig()\n",
    "    dataingestionconfig=DataIngestionConfig(trainingpipelineconfig)\n",
    "    dataingestion=DataIngestion(dataingestionconfig)\n",
    "    logging.info('INITIATED DATA INGESTION COMPONENT')\n",
    "    dataingestionartifact=dataingestion.initiate_data_ingestion()\n",
    "    print(dataingestionartifact)\n",
    "    logging.info(f'{STAGE_NAME} completed')\n",
    "except Exception as e:\n",
    "    raise NetworkSecurityException(e,sys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74bf18c4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
