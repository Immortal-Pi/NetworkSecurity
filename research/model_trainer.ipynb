{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05be63ec",
   "metadata": {},
   "source": [
    "# model trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef6f8778",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants \n",
    "import os \n",
    "\"\"\" \n",
    "Model Traniner related constant starts with MODEL TRAINER VAR NAME\n",
    "\"\"\"\n",
    "MODEL_TRAINER_DIR_NAME: str = 'model_trainer'\n",
    "MODEL_TRAINER_TRAINED_MODEL_DIR: str='trained_model'\n",
    "MODEL_TRAINER_TRAINED_MODEL_NAME: str= 'model.pkl'\n",
    "MODEL_TRAINER_EXPECTED_SCORE: float = 0.6 \n",
    "MODEL_TRAINER_OVER_FITTING_UNDER_FITTING_THRESHOLD: float= 0.05 \n",
    "\n",
    "SAVED_MODEL_DIR=os.path.join('saved_models')\n",
    "MODEL_FILE_NAME='model.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36952273",
   "metadata": {},
   "outputs": [],
   "source": [
    "# artifact entity\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class ClassificationMetricArtifact:\n",
    "    f1_score: float\n",
    "    precision_score: float\n",
    "    recall_score: float \n",
    "\n",
    "@dataclass\n",
    "class ModelTrainerArtifact:\n",
    "    trained_model_file_path: str \n",
    "    train_metric_artifact: ClassificationMetricArtifact\n",
    "    test_metric_artifact: ClassificationMetricArtifact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "81d5c98e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config entity \n",
    "from NetworkSecurity.entity.config_entity import TrainingPipelineConfig\n",
    "from NetworkSecurity.constants import training_pipeline\n",
    "\n",
    "import os \n",
    "class ModelTraninerConfig:\n",
    "    def __init__(self,training_pipeline_config: TrainingPipelineConfig):\n",
    "        self.model_trainer_dir: str = os.path.join(\n",
    "            training_pipeline_config.artifact_dir, training_pipeline.MODEL_TRAINER_DIR_NAME\n",
    "        )\n",
    "        self.trained_model_file_path: str = os.path.join(\n",
    "            self.model_trainer_dir, training_pipeline.MODEL_TRAINER_TRAINED_MODEL_DIR, training_pipeline.MODEL_TRAINER_TRAINED_MODEL_NAME\n",
    "        )\n",
    "        self.expected_accuracy:float=training_pipeline.MODEL_TRAINER_EXPECTED_SCORE\n",
    "        self.overfitting_underfitting_threshold= training_pipeline.MODEL_TRAINER_OVER_FITTING_UNDER_FITTING_THRESHOLD\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "787d4c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# component\n",
    "import os \n",
    "import sys \n",
    "from NetworkSecurity.exception.exception import NetworkSecurityException\n",
    "from NetworkSecurity.logging.logger import logging\n",
    "from NetworkSecurity.entity.config_entity import ModelTraninerConfig\n",
    "from NetworkSecurity.utils.main_utils.utils import save_object,load_object\n",
    "from NetworkSecurity.utils.main_utils.utils import load_numpy_array_data,evaluate_models\n",
    "from NetworkSecurity.utils.ml_utils.metric.classification_metric import get_classification_score\n",
    "from NetworkSecurity.utils.ml_utils.model.estimator import NetworkModel\n",
    "from NetworkSecurity.entity.artifact_entity import DataTransformationArtifact,ModelTrainerArtifact\n",
    "from NetworkSecurity.entity.config_entity import ModelTraninerConfig\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import (\n",
    "    AdaBoostClassifier,\n",
    "    GradientBoostingClassifier,\n",
    "    RandomForestClassifier,\n",
    ")\n",
    "\n",
    "class ModelTrainer:\n",
    "    def __init__(self,model_trainer_config:ModelTraninerConfig,data_transformation_artifact:DataTransformationArtifact):\n",
    "        try:\n",
    "            self.model_trainer_config=model_trainer_config\n",
    "            self.data_transformation_artifact=data_transformation_artifact \n",
    "\n",
    "        except Exception as e:\n",
    "            raise NetworkSecurityException(e,sys)\n",
    "\n",
    "    def train_model(self,xtrain,ytrain,xtest,ytest):\n",
    "        models={\n",
    "            'Random Forest':RandomForestClassifier(verbose=1),\n",
    "            'Decision Tree':DecisionTreeClassifier(),\n",
    "            'Gradient Boosting':GradientBoostingClassifier(verbose=1),\n",
    "            'Logistic Regression':LogisticRegression(verbose=1),\n",
    "            'AdaBoost':AdaBoostClassifier(),\n",
    "        } \n",
    "\n",
    "        # hyper parameter tuning \n",
    "        params={\n",
    "            'Decision Tree':{\n",
    "                'criterion':['gini','entropy','log_loss'],\n",
    "                # 'splitter':['best','random'],\n",
    "                # 'max_features':['sqrt','log2'],\n",
    "            },\n",
    "            'Random Forest':{\n",
    "                # 'max_features':['sqrt','log2'],\n",
    "                # 'criterion':['gini','entropy','log_loss'],\n",
    "                'n_estimators':[8,16,32,64,128,256]\n",
    "            },\n",
    "            'Gradient Boosting':{\n",
    "                # 'loss':['log_loss','exponential'],\n",
    "                'learning_rate':[.1,.01,.05,.001],\n",
    "                'subsample':[0.6,0.7,0.75,0.8,0.85,0.9],\n",
    "                # 'criterion':['squared_error','friedman_mse'],\n",
    "                # 'max_featues':['auto','sqrt','log2'],\n",
    "                'n_estimators':[8,16,32,64,128,256]\n",
    "            },\n",
    "            'Logistic Regression':{},\n",
    "            'AdaBoost':{\n",
    "                'learning_rate':[.1,.01,0.5,0.001],\n",
    "                'n_estimators':[8,16,32,64,128,256]\n",
    "            }\n",
    "        }\n",
    "        model_report:dict=evaluate_models(xtrain,ytrain,xtest,ytest,models,params)\n",
    "\n",
    "        # get the best model score from dict\n",
    "        best_model_score=max(sorted(model_report.values()))\n",
    "        best_model_name=list(model_report.keys())[\n",
    "            list(model_report.values()).index(best_model_score)\n",
    "        ]\n",
    "        best_model=models[best_model_name]\n",
    "        y_train_pred=best_model.predict(xtrain)\n",
    "\n",
    "        classification_train_metric=get_classification_score(y_true=ytrain,y_pred=y_train_pred)\n",
    "        # function to track the mlflow \n",
    "\n",
    "        y_test_pred=best_model.predict(xtrain)\n",
    "        classification_test_metric=get_classification_score(y_true=ytest,y_pred=y_test_pred)\n",
    "        \n",
    "        # load the pickle file \n",
    "        preprocessor=load_object(file_path=self.data_transformation_artifact.transformed_object_file_path)\n",
    "\n",
    "        model_dir_path=os.path.dirname(self.model_trainer_config.trained_model_file_path)\n",
    "        os.makedirs(model_dir_path,exist_ok=True)\n",
    "\n",
    "        NetworkModel=NetworkModel(preprocessor=preprocessor,model=best_model)\n",
    "        save_object(self.model_trainer_config.trained_model_file_path,obj=NetworkModel)\n",
    "\n",
    "        ## Model Trainer Aritifact \n",
    "        model_trainer_artifact=ModelTrainerArtifact(trained_model_file_path=self.model_trainer_config.trained_model_file_path,\n",
    "                             train_metric_artifact=classification_train_metric,\n",
    "                             test_metric_artifact=classification_test_metric\n",
    "                             )\n",
    "        logging.info(f'Model trainer artifact: {model_trainer_artifact}')\n",
    "        return model_trainer_artifact\n",
    "\n",
    "    def initiate_model_trainer(self)->ModelTrainerArtifact:\n",
    "        try:\n",
    "            train_file_path=self.data_transformation_artifact.transformed_train_file_path\n",
    "            test_file_path=self.data_transformation_artifact.transfromed_test_file_path\n",
    "\n",
    "            # loading training array and testing array\n",
    "            train_arr=load_numpy_array_data(train_file_path)\n",
    "            test_arr=load_numpy_array_data(test_file_path)\n",
    "            xtrain,ytrain,xtest,ytest=(\n",
    "                train_arr[:,:-1],\n",
    "                train_arr[:,-1],\n",
    "                test_arr[:,:-1],\n",
    "                test_arr[:,-1],\n",
    "            )\n",
    "            model_trainer_artifact=self.train_model(xtrain,ytrain)\n",
    "            return model_trainer_artifact\n",
    "\n",
    "\n",
    "        except Exception as e:\n",
    "            raise NetworkSecurityException(e,sys)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a0442e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# add to main.py file "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
