{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2642690b",
   "metadata": {},
   "source": [
    "# data validation \n",
    "- datatypes \n",
    "- data drift \n",
    "- same schema\n",
    "- validate column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d1c094e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants \n",
    "\"\"\" \n",
    "Data Validation related constants \n",
    "\"\"\"\n",
    "DATA_VALIDATION_DIR_NAME: str = 'data_validation'\n",
    "DATA_VALIDATION_VALID_DIR: str = 'validated'\n",
    "DATA_VALIDATION_INVALID_DIR: str = 'invalid'\n",
    "DATA_VALIDATION_DRIFT_REPORT_DIR: str = 'drift_report'\n",
    "DATA_VALIDATION_DRIFT_REPRT_FILE_NAME: str = 'report.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbdf033",
   "metadata": {},
   "outputs": [],
   "source": [
    "# entity \n",
    "from dataclasses import dataclass \n",
    "\n",
    "@dataclass\n",
    "class DataValidationArtifiact:\n",
    "    valdation_status: bool\n",
    "    valid_train_file_path: str \n",
    "    valid_test_file_path: str \n",
    "    invalid_train_file_path: str \n",
    "    invalid_test_file_path: str \n",
    "    drift_report_filepath: str \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b32be84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config entity \n",
    "from NetworkSecurity.constants import training_pipeline\n",
    "from NetworkSecurity.config.configuration import TrainingPipelineConfig\n",
    "import os \n",
    "\n",
    "class DataValidationConfig: \n",
    "    def __init__(self,training_pipeline_config:TrainingPipelineConfig):\n",
    "        self.data_validation_dir: str = os.path.join(training_pipeline_config.artifact_dir,training_pipeline.DATA_VALIDATION_DIR_NAME)\n",
    "        self.valid_data_dir: str = os.path.join(self.data_validation_dir,training_pipeline.DATA_VALIDATION_VALID_DIR)\n",
    "        self.invalid_data_dir: str = os.path.join(self.data_validation_dir, training_pipeline.DATA_VALIDATION_INVALID_DIR)\n",
    "        self.valid_train_file_path: str =os.path.join(self.valid_data_dir, training_pipeline.TRAIN_FILE_NAME)\n",
    "        self.valid_test_file_path: str = os.path.join(self.valid_data_dir, training_pipeline.TEST_FILE_NAME)\n",
    "        self.invalid_train_file_path: str = os.path.join(self.invalid_data_dir, training_pipeline.TRAIN_FILE_NAME)\n",
    "        self.invalid_test_file_path: str = os.path.join(self.invalid_data_dir, training_pipeline.TEST_FILE_NAME)\n",
    "        self.drift_report_file_path: str = os.path.join(self.data_validation_dir, \n",
    "                                                        training_pipeline.DATA_VALIDATION_DRIFT_REPORT_DIR, \n",
    "                                                        training_pipeline.DATA_VALIDATION_DRIFT_REPRT_FILE_NAME\n",
    "                                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92758b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create schema.yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1309bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# component \n",
    "from NetworkSecurity.entity.artifact_entity import DataIngestionArtifact, DataValidationAritifact\n",
    "from NetworkSecurity.entity.config_entity import DataIngestionConfig\n",
    "from NetworkSecurity.exception.exception import NetworkSecurityException\n",
    "from NetworkSecurity.logging.logger import logging\n",
    "from scipy.stats import ks_2samp # check 2 samples for data drift \n",
    "from NetworkSecurity.constants.training_pipeline import SCHEMA_FILE_PATH\n",
    "from NetworkSecurity.utils.main_utils.utils import read_yaml_file, write_yaml_file\n",
    "import pandas as pd \n",
    "import os, sys \n",
    "from NetworkSecurity.components.data_ingestion import DataIngestion\n",
    "\n",
    "class DataValidation:\n",
    "    def __init__(self, data_ingestion_artifact: DataIngestionArtifact,\n",
    "                 data_validation_config: DataValidationConfig):\n",
    "        try:\n",
    "            self.data_ingestion_artifact=data_ingestion_artifact\n",
    "            self.data_validation_config=data_validation_config\n",
    "            self._schema_config=read_yaml_file(SCHEMA_FILE_PATH)\n",
    "        except Exception as e:\n",
    "            raise NetworkSecurityException(e,sys)\n",
    "\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def read_data(file_path)->pd.DataFrame:\n",
    "        try:\n",
    "            return pd.read_csv(file_path)\n",
    "        except Exception as e:\n",
    "            raise NetworkSecurityException(e,sys)\n",
    "\n",
    "\n",
    "    \n",
    "    def validate_numbers_of_columns(self,dataframe:pd.DataFrame)->bool:\n",
    "        try:\n",
    "            number_of_columns=len(self._schema_config) \n",
    "            logging.info(f'Required number of columns {number_of_columns}')\n",
    "            logging.info(f'Data frame has columns: {len(dataframe.columns)}')\n",
    "            if len(dataframe.columns)==number_of_columns:\n",
    "                return True \n",
    "            return False \n",
    "        except Exception as e:\n",
    "            raise NetworkSecurityException(e,sys)\n",
    "\n",
    "    \n",
    "    \n",
    "    def detect_dataset_drift(self,base_df,current_df,threshold=0.05)-> bool:\n",
    "        try:\n",
    "            satus=True\n",
    "            report={}\n",
    "            for column in base_df.columns:\n",
    "                d1=base_df[column]\n",
    "                d2=current_df[column]\n",
    "                is_same_dist=ks_2samp(d1,d2)\n",
    "                if threshold<=is_same_dist.pvalue:\n",
    "                    is_found=False\n",
    "                else:\n",
    "                    is_found=True \n",
    "                report.update(\n",
    "                    {column:{\n",
    "                        'p_value':float(is_same_dist.pvalue),\n",
    "                        'drift_status':is_found\n",
    "                    }}\n",
    "                )\n",
    "            drift_report_file_path = self.data_validation_config.drift_report_file_path\n",
    "            \n",
    "            # create directory\n",
    "            dir_path= os.path.dirname(drift_report_file_path)\n",
    "            os.makedirs(dir_path,exist_ok=True)\n",
    "            write_yaml_file(file_path=drift_report_file_path,content=report)\n",
    "\n",
    "        except Exception as e:\n",
    "            raise NetworkSecurityException(e,sys)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    def initiate_data_validation(self)-> DataValidationAritifact:\n",
    "        try:\n",
    "            train_file_path=self.data_ingestion_artifact.trained_file_path\n",
    "            test_file_path=self.data_ingestion_artifact.test_file_path\n",
    "\n",
    "            ## read the data from train and etst \n",
    "            train_dataframe=DataValidation.read_data(train_file_path)\n",
    "            test_dataframe=DataValidation.read_data(test_file_path)\n",
    "\n",
    "            # validate number of columns \n",
    "            status=self.validate_numbers_of_columns(dataframe=train_dataframe)\n",
    "            if not status:\n",
    "                error_message=f'{error_message} Train dataframe does not contain all columns \\n'\n",
    "            \n",
    "            status=self.validate_numbers_of_columns(dataframe=test_dataframe)\n",
    "            if not status:\n",
    "                error_message=f'{error_message} Test dataframe does not contain all columns \\n'\n",
    "\n",
    "            ## check for numerical columns\n",
    "\n",
    "            ## check for data drift \n",
    "            status=self.detect_dataset_drift(base_df=train_dataframe,current_df=test_dataframe)\n",
    "            dir_path=os.path.dirname(self.data_validation_config.valid_train_file_path)\n",
    "            os.mkdirs(dir_path,exist_ok=True)\n",
    "\n",
    "            train_dataframe.to_csv(self.data_validation_config.valid_train_file_path, index=False, header=True)\n",
    "            test_dataframe.to_csv(self.data_validation_config.valid_test_file_path, index=False, header=True)\n",
    "\n",
    "            data_validation_artifact=DataValidationAritifact(\n",
    "                validation_status=status,\n",
    "                valid_train_file_path=self.data_ingestion_artifact.trained_file_path,\n",
    "                valid_test_file_path=self.data_ingestion_artifact.test_file_path,\n",
    "                invalid_train_file_path=None,\n",
    "                invalid_test_file_path=None,\n",
    "                drift_report_file_path=self.data_validation_config.drift_report_file_path\n",
    "            )\n",
    "            return data_validation_artifact\n",
    "        except Exception as e:\n",
    "            raise NetworkSecurityException(e,sys)\n",
    "        \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "10b07798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataIngestionArtifact(trained_file_path='Artifacts\\\\05_14_2025_11_51_52\\\\data_ingestion\\\\ingested\\\\train.csv', test_file_path='Artifacts\\\\05_14_2025_11_51_52\\\\data_ingestion\\\\ingested\\\\test.csv')\n"
     ]
    },
    {
     "ename": "NetworkSecurityException",
     "evalue": "Error occured in python script name [C:\\Users\\26amr\\AppData\\Local\\Temp\\ipykernel_24348\\3967426075.py] line number [10] error message [Error occured in python script name [C:\\Users\\26amr\\AppData\\Local\\Temp\\ipykernel_24348\\685533584.py] line number [19] error message [Error occured in python script name [d:\\pythonprojects\\networksecurity\\src\\NetworkSecurity\\utils\\main_utils\\utils.py] line number [12] error message [[Errno 2] No such file or directory: 'data_schema\\\\schema.yaml']]]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[1;32md:\\pythonprojects\\networksecurity\\src\\NetworkSecurity\\utils\\main_utils\\utils.py:12\u001b[0m, in \u001b[0;36mread_yaml_file\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 12\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfile_path\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m yaml_file:\n\u001b[0;32m     13\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m yaml\u001b[38;5;241m.\u001b[39msafe_load(yaml_file)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'data_schema\\\\schema.yaml'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mNetworkSecurityException\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[13], line 19\u001b[0m, in \u001b[0;36mDataValidation.__init__\u001b[1;34m(self, data_ingestion_artifact, data_validation_config)\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_validation_config\u001b[38;5;241m=\u001b[39mdata_validation_config\n\u001b[1;32m---> 19\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_schema_config\u001b[38;5;241m=\u001b[39m\u001b[43mread_yaml_file\u001b[49m\u001b[43m(\u001b[49m\u001b[43mSCHEMA_FILE_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32md:\\pythonprojects\\networksecurity\\src\\NetworkSecurity\\utils\\main_utils\\utils.py:15\u001b[0m, in \u001b[0;36mread_yaml_file\u001b[1;34m(file_path)\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 15\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NetworkSecurityException(e,sys) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mNetworkSecurityException\u001b[0m: Error occured in python script name [d:\\pythonprojects\\networksecurity\\src\\NetworkSecurity\\utils\\main_utils\\utils.py] line number [12] error message [[Errno 2] No such file or directory: 'data_schema\\\\schema.yaml']",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNetworkSecurityException\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 10\u001b[0m\n\u001b[0;32m      9\u001b[0m data_validation_config\u001b[38;5;241m=\u001b[39mDataValidationConfig(trainingpipelineconfig)\n\u001b[1;32m---> 10\u001b[0m data_validation\u001b[38;5;241m=\u001b[39m\u001b[43mDataValidation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataingestionconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43mdata_validation_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m logging\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mInitiate the data validation\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "Cell \u001b[1;32mIn[13], line 21\u001b[0m, in \u001b[0;36mDataValidation.__init__\u001b[1;34m(self, data_ingestion_artifact, data_validation_config)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 21\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NetworkSecurityException(e,sys)\n",
      "\u001b[1;31mNetworkSecurityException\u001b[0m: Error occured in python script name [C:\\Users\\26amr\\AppData\\Local\\Temp\\ipykernel_24348\\685533584.py] line number [19] error message [Error occured in python script name [d:\\pythonprojects\\networksecurity\\src\\NetworkSecurity\\utils\\main_utils\\utils.py] line number [12] error message [[Errno 2] No such file or directory: 'data_schema\\\\schema.yaml']]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mNetworkSecurityException\u001b[0m                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28mprint\u001b[39m(data_validation_artifact)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m---> 16\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m NetworkSecurityException(e,sys)\n",
      "\u001b[1;31mNetworkSecurityException\u001b[0m: Error occured in python script name [C:\\Users\\26amr\\AppData\\Local\\Temp\\ipykernel_24348\\3967426075.py] line number [10] error message [Error occured in python script name [C:\\Users\\26amr\\AppData\\Local\\Temp\\ipykernel_24348\\685533584.py] line number [19] error message [Error occured in python script name [d:\\pythonprojects\\networksecurity\\src\\NetworkSecurity\\utils\\main_utils\\utils.py] line number [12] error message [[Errno 2] No such file or directory: 'data_schema\\\\schema.yaml']]]"
     ]
    }
   ],
   "source": [
    "try: \n",
    "    trainingpipelineconfig=TrainingPipelineConfig()\n",
    "    dataingestionconfig=DataIngestionConfig(trainingpipelineconfig)\n",
    "    data_ingestion=DataIngestion(dataingestionconfig)\n",
    "    logging.info('Initiate the data ingesion')\n",
    "    dataingestionartifact=data_ingestion.initiate_data_ingestion()\n",
    "    logging.info('data initiation completed')\n",
    "    print(dataingestionartifact)\n",
    "    data_validation_config=DataValidationConfig(trainingpipelineconfig)\n",
    "    data_validation=DataValidation(dataingestionconfig,data_validation_config)\n",
    "    logging.info('Initiate the data validation')\n",
    "    data_validation_artifact=data_validation.initiate_data_validation()\n",
    "    logging.info('Data validation completed')\n",
    "    print(data_validation_artifact)\n",
    "except Exception as e:\n",
    "    raise NetworkSecurityException(e,sys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a0fbcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
