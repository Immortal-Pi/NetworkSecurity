{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2642690b",
   "metadata": {},
   "source": [
    "# data validation \n",
    "- datatypes \n",
    "- data drift \n",
    "- same schema\n",
    "- validate column\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d1c094e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constants \n",
    "\"\"\" \n",
    "Data Validation related constants \n",
    "\"\"\"\n",
    "DATA_VALIDATION_DIR_NAME: str = 'data_validation'\n",
    "DATA_VALIDATION_VALID_DIR: str = 'validated'\n",
    "DATA_VALIDATION_INVALID_DIR: str = 'invalid'\n",
    "DATA_VALIDATION_DRIFT_REPORT_DIR: str = 'drift_report'\n",
    "DATA_VALIDATION_DRIFT_REPRT_FILE_NAME: str = 'report.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b32be84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# config \n",
    "from NetworkSecurity.constants import training_pipeline\n",
    "from NetworkSecurity.config.configuration import TrainingPipelineConfig\n",
    "import os \n",
    "\n",
    "class DataValidationConfig: \n",
    "    def __init__(self,training_pipeline_config:TrainingPipelineConfig):\n",
    "        self.data_validation_dir: str = os.path.join(training_pipeline_config.artifact_dir,training_pipeline.DATA_VALIDATION_DIR_NAME)\n",
    "        self.valid_data_dir: str = os.path.join(self.data_validation_dir,training_pipeline.DATA_VALIDATION_VALID_DIR)\n",
    "        self.invalid_data_dir: str = os.path.join(self.data_validation_dir, training_pipeline.DATA_VALIDATION_INVALID_DIR)\n",
    "        self.valid_train_file_path: str =os.path.join(self.valid_data_dir, training_pipeline.TRAIN_FILE_NAME)\n",
    "        self.valid_test_file_path: str = os.path.join(self.valid_data_dir, training_pipeline.TEST_FILE_NAME)\n",
    "        self.invalid_train_file_path: str = os.path.join(self.invalid_data_dir, training_pipeline.TRAIN_FILE_NAME)\n",
    "        self.invalid_test_file_path: str = os.path.join(self.invalid_data_dir, training_pipeline.TEST_FILE_NAME)\n",
    "        self.drift_report_file_path: str = os.path.join(self.data_validation_dir, \n",
    "                                                        training_pipeline.DATA_VALIDATION_DRIFT_REPORT_DIR, \n",
    "                                                        training_pipeline.DATA_VALIDATION_DRIFT_REPRT_FILE_NAME\n",
    "                                                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92758b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create schema.yaml file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1309bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# component \n",
    "from NetworkSecurity.entity.artifact_entity import DataIngestionArtifact, DataValidationAritifact\n",
    "# from NetworkSecurity.entity.config_entity import D\n",
    "from NetworkSecurity.exception.exception import NetworkSecurityException\n",
    "from NetworkSecurity.logging.logger import logging\n",
    "from scipy.stats import ks_2samp # check 2 samples for data drift \n",
    "from NetworkSecurity.constants.training_pipeline import SCHEMA_FILE_PATH\n",
    "from NetworkSecurity.utils.main_utils.utils import read_yaml_file\n",
    "import pandas as pd \n",
    "import os, sys \n",
    "\n",
    "class DataValidation:\n",
    "    def __init__(self, data_ingestion_artifact: DataIngestionArtifact,\n",
    "                 data_validation_config: DataValidationConfig):\n",
    "        try:\n",
    "            self.data_ingestion_artifact=data_ingestion_artifact\n",
    "            self.data_validation_config=data_validation_config\n",
    "            self._schema_config=read_yaml_file(SCHEMA_FILE_PATH)\n",
    "        except Exception as e:\n",
    "            raise NetworkSecurityException(e,sys)\n",
    "        \n",
    "    @staticmethod\n",
    "    def read_data(file_path)->pd.DataFrame:\n",
    "        try:\n",
    "            return pd.read_csv(file_path)\n",
    "        except Exception as e:\n",
    "            raise NetworkSecurityException(e,sys)\n",
    "\n",
    "    def validate_numbers_of_columns(self,dataframe:pd.DataFrame)->bool:\n",
    "        try:\n",
    "            number_of_columns=len(self._schema_config) \n",
    "            logging.info(f'Required number of columns {number_of_columns}')\n",
    "            logging.info(f'Data frame has columns: {len(dataframe.columns)}')\n",
    "            if len(dataframe.columns)==number_of_columns:\n",
    "                return True \n",
    "            return False \n",
    "        except Exception as e:\n",
    "            raise NetworkSecurityException(e,sys)\n",
    "\n",
    "    def detect_dataset_drift(self,base_df,current_df,threshold=0.05,)\n",
    "    def initiate_data_validation(self)-> DataValidationAritifact:\n",
    "        try:\n",
    "            train_file_path=self.data_ingestion_artifact.trained_file_path\n",
    "            test_file_path=self.data_ingestion_artifact.test_file_path\n",
    "\n",
    "            ## read the data from train and etst \n",
    "            train_dataframe=DataValidation.read_data(train_file_path)\n",
    "            test_dataframe=DataValidation.read_data(test_file_path)\n",
    "\n",
    "            # validate number of columns \n",
    "            status=self.validate_numbers_of_columns(dataframe=train_dataframe)\n",
    "            if not status:\n",
    "                error_message=f'{error_message} Train dataframe does not contain all columns \\n'\n",
    "            \n",
    "            status=self.validate_numbers_of_columns(dataframe=test_dataframe)\n",
    "            if not status:\n",
    "                error_message=f'{error_message} Test dataframe does not contain all columns \\n'\n",
    "\n",
    "            ## check for numerical columns\n",
    "            ## check for data drift \n",
    "            \n",
    "        except Exception as e:\n",
    "            raise NetworkSecurityException(e,sys)\n",
    "        \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10b07798",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
